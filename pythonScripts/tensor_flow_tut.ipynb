{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.13.3\n",
      "scipy 0.19.1\n",
      "tensorflow 1.11.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print 'numpy ' + np.__version__\n",
    "print 'scipy ' + sp.__version__\n",
    "print 'tensorflow ' + tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Initialize two constants\n",
    "x1 = tf.constant([1,2,3,4])\n",
    "x2 = tf.constant([5,6,7,8])\n",
    "\n",
    "# Multiply\n",
    "result = tf.multiply(x1, x2)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# TRIVIAL LOSS FUNCTION\n",
    "\n",
    "# Model Parameters\n",
    "W = tf.Variable([0.3],tf.float32)\n",
    "b = tf.Variable([-0.3],tf.float32)\n",
    "# Inputs and Outputs\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "linear_model = W * x + b\n",
    "\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Loss\n",
    "squared_delta = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_delta)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# To run you need to create a session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(sess.run(loss,{x:[1,2,3,4],y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model Parameters\n",
    "W = tf.Variable([0.3],tf.float32)\n",
    "b = tf.Variable([-0.3],tf.float32)\n",
    "# Inputs and Outputs\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "linear_model = W * x + b\n",
    "\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Loss\n",
    "squared_delta = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_delta)\n",
    "\n",
    "# Optimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# To run you need to create a session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(0,1000):\n",
    "    sess.run(train,{x:[1,2,3,4],y:[0,-1,-2,-3]})\n",
    "\n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CATEGORIZE NUMBERS (MNIST)\n",
    "Two different implementation of the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.1994 - acc: 0.9406\n",
      "Epoch 2/11\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0803 - acc: 0.9753\n",
      "Epoch 3/11\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0520 - acc: 0.9830\n",
      "Epoch 4/11\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0366 - acc: 0.9883\n",
      "Epoch 5/11\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.0268 - acc: 0.9913\n",
      "Epoch 6/11\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.0213 - acc: 0.9929\n",
      "Epoch 7/11\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.0164 - acc: 0.9945\n",
      "Epoch 8/11\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0147 - acc: 0.9951\n",
      "Epoch 9/11\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.0115 - acc: 0.9962\n",
      "Epoch 10/11\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0107 - acc: 0.9965\n",
      "Epoch 11/11\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0107 - acc: 0.9967\n",
      "10000/10000 [==============================] - 1s 109us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.080438575388109168, 0.98040000000000005]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=7)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.3144 - acc: 0.9130\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "\n",
      "TEST LOSS:  0.175528795186\n",
      "TEST ACC :  0.9488\n",
      "\n",
      "Percent likelihoods of image being 0-9: \n",
      "[0.002, 99.231, 0.059, 0.167, 0.005, 0.008, 0.008, 0.232, 0.269, 0.018]\n",
      "Predicted Letter:  1\n"
     ]
    }
   ],
   "source": [
    "layers = 1\n",
    "epochs = 1\n",
    "\n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(28, 28))) # Flatten input layer from 2D [26x26] to 1D [676]\n",
    "# Each model.add command adds a new layer to the NN.\n",
    "# First arg is number of neurons. Second is activation function\n",
    "for i in range(layers):\n",
    "    model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "# Returns an array of 10 probability scores that sum to 1\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax)) # Output\n",
    "\n",
    "# adam is default optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train your model\n",
    "model.fit(x_train,y_train,epochs=epochs)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print ''\n",
    "print 'TEST LOSS: ',test_loss\n",
    "print 'TEST ACC : ',test_acc\n",
    "print ''\n",
    "\n",
    "# Now we look at the model's predictions themselves\n",
    "predictions = model.predict(x_test)\n",
    "first_prediction = predictions[5]\n",
    "print 'Percent likelihoods of image being 0-9: '\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint( [round(elem*100,3) for elem in first_prediction] )\n",
    "print 'Predicted Number: ',np.argmax(first_prediction)\n",
    "#plt.imshow(x_test[0], cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
